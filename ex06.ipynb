{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0hoB4Jdw1EF",
        "outputId": "9e5ac7be-012f-4f75-b801-58441d594eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "file_path = 'war.txt'  # Replace with the path to your text file\n",
        "text = read_text_file(file_path)\n"
      ],
      "metadata": {
        "id": "VOnLVRqHw2FE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "def get_verbs(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tagged_tokens = pos_tag(tokens)\n",
        "    verbs = [word for word, pos in tagged_tokens if pos.startswith('VB')]\n",
        "    return verbs\n",
        "\n",
        "verbs = get_verbs(text)\n"
      ],
      "metadata": {
        "id": "ntvvz9niw_uR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_synonyms_antonyms(verb):\n",
        "    synonyms = []\n",
        "    antonyms = []\n",
        "\n",
        "    for synset in wn.synsets(verb, pos=wn.VERB):\n",
        "        for lemma in synset.lemmas():\n",
        "            synonyms.append(lemma.name())\n",
        "            if lemma.antonyms():\n",
        "                antonyms.append(lemma.antonyms()[0].name())\n",
        "\n",
        "    return set(synonyms), set(antonyms)\n",
        "\n",
        "verb_synonyms_antonyms = {}\n",
        "for verb in verbs:\n",
        "    synonyms, antonyms = get_synonyms_antonyms(verb)\n",
        "    verb_synonyms_antonyms[verb] = {'synonyms': synonyms, 'antonyms': antonyms}\n",
        "\n",
        "for verb, data in verb_synonyms_antonyms.items():\n",
        "    print(f\"Verb: {verb}\")\n",
        "    print(f\"Synonyms: {', '.join(data['synonyms'])}\")\n",
        "    print(f\"Antonyms: {', '.join(data['antonyms']) if data['antonyms'] else 'No antonyms found.'}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujjgDh0LxCw6",
        "outputId": "b4780c5e-c5a6-4785-b827-b421fdab261a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verb: is\n",
            "Synonyms: comprise, be, equal, live, embody, make_up, follow, personify, represent, constitute, cost, exist\n",
            "Antonyms: differ\n",
            "\n",
            "Verb: harrowing\n",
            "Synonyms: disk, harrow\n",
            "Antonyms: No antonyms found.\n",
            "\n",
            "Verb: impacts\n",
            "Synonyms: bear_on, affect, touch, touch_on, bear_upon, impact\n",
            "Antonyms: No antonyms found.\n",
            "\n",
            "Verb: endure\n",
            "Synonyms: tolerate, hold_out, brook, survive, persist, suffer, live, go, stick_out, stomach, endure, prevail, last, digest, put_up, abide, support, weather, hold_up, stand, bear, wear, brave_out, live_on, die_hard, brave, run\n",
            "Antonyms: enjoy\n",
            "\n",
            "Verb: become\n",
            "Synonyms: turn, get, suit, go, become\n",
            "Antonyms: No antonyms found.\n",
            "\n",
            "Verb: deafening\n",
            "Synonyms: deafen, deaf\n",
            "Antonyms: No antonyms found.\n",
            "\n",
            "Verb: echo\n",
            "Synonyms: reverberate, resound, echo, repeat, recall, ring\n",
            "Antonyms: No antonyms found.\n",
            "\n",
            "Verb: ends\n",
            "Synonyms: cease, stop, terminate, end, finish\n",
            "Antonyms: begin\n",
            "\n",
            "Verb: witness\n",
            "Synonyms: find, see, witness\n",
            "Antonyms: No antonyms found.\n",
            "\n",
            "Verb: unfold\n",
            "Synonyms: stretch, blossom_out, blossom, blossom_forth, open, extend, unfold, stretch_out, spread_out, spread\n",
            "Antonyms: fold\n",
            "\n",
            "Verb: embody\n",
            "Synonyms: substantiate, body_forth, be, incarnate, embody, personify\n",
            "Antonyms: No antonyms found.\n",
            "\n",
            "Verb: face\n",
            "Synonyms: look, face_up, confront, face, front, present\n",
            "Antonyms: avoid, back\n",
            "\n",
            "Verb: carrying\n",
            "Synonyms: comport, stock, gestate, conduct, dribble, express, deport, convey, hold, sway, take, pack, transmit, persuade, expect, contain, transport, extend, stockpile, carry, impart, behave, have_a_bun_in_the_oven, bear, acquit, post, channel, run\n",
            "Antonyms: No antonyms found.\n",
            "\n",
            "Verb: fallen\n",
            "Synonyms: flow, fall_down, fall, lessen, hang, settle, go_down, shine, return, diminish, light, accrue, decrease, devolve, pass, come, come_down, strike, precipitate, descend\n",
            "Antonyms: rise, ascend, increase\n",
            "\n",
            "Verb: find\n",
            "Synonyms: chance, ascertain, find, feel, happen, incur, notice, discover, see, recover, come_up, encounter, bump, get_hold, rule, regain, get, witness, observe, receive, obtain, retrieve, find_out, determine, detect, line_up, find_oneself\n",
            "Antonyms: lose\n",
            "\n",
            "Verb: forged\n",
            "Synonyms: spurt, mould, formulate, fake, counterfeit, work, contrive, mold, invent, hammer, excogitate, devise, shape, form, forge, fashion, spirt\n",
            "Antonyms: No antonyms found.\n",
            "\n",
            "Verb: changed\n",
            "Synonyms: modify, alter, commute, vary, interchange, shift, switch, exchange, change, transfer, convert, deepen\n",
            "Antonyms: stay\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aU7bo_hkxUYP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}